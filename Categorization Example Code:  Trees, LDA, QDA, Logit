require(MASS)
require(nnet)
require(lars)
require(rpart)

iterations = 100
trainingfraction = .6

data = spam
data = as.matrix(data)
data = data[,c(58,1:57)]
data=data.frame(data)

len = nrow(data)
sample.size = round(trainingfraction*len)

#need trees, logistic regressions, LDA, and QDA
rp = array(dim=c(iterations,1))
rpcm = array(dim = c(2,2))
rpcm[1]=0
rpcm[2]=0
rpcm[3]=0
rpcm[4]=0

log = array(dim=c(iterations,1))
logcm = array(dim = c(2,2))
logcm[1]=0
logcm[2]=0
logcm[3]=0
logcm[4]=0

lda = array(dim=c(iterations,1))
ldacm = array(dim = c(2,2))
ldacm[1]=0
ldacm[2]=0
ldacm[3]=0
ldacm[4]=0

qda = array(dim=c(iterations,1))
qdacm = array(dim = c(2,2))
qdacm[1]=0
qdacm[2]=0
qdacm[3]=0
qdacm[4]=0

for(i in 1:iterations){

	#seleect the training subsample
	train = array(0,dim=c(len,1))
	train[sample(len,size=sample.size)] = 1
		
	#get the testing subsample observed values
	test = data[train == 0,1]



	#Tree model
	rpm = rpart(spam~.,cp = 0,data = data[train==1,] )
	rpp = predict(rpm, new = data[train==0,])
	rppp = rpp >.5
	rp[i]=cor(rppp,test)^2
	
	r= xtabs(~test+rppp)
	rpcm[1] =r[1] + rpcm[1]
	rpcm[2] =r[2] + rpcm[2]
	rpcm[3] =r[3] + rpcm[3]
	rpcm[4] =r[4] + rpcm[4]
	

	#logistic model
	logm = glm(spam~.,data = data[train==1,], family = binomial)
	logp = predict(logm, new = data[train==0,])
	logpp = logp > .5
	log[i]=cor(logpp,test)
	
	r= xtabs(~test+logpp)
	logcm[1] =r[1] +logcm[1]
	logcm[2] =r[2] +logcm[2]
	logcm[3] =r[3] +logcm[3]
	logcm[4] =r[4] +logcm[4]
	
	

	#lda model
	ldam = lda(spam~.,data=data[train ==1,])
	ldap = predict(ldam ,type = "class",new = data[train==0,])
	ldapp = logp > .5
	lda[i] = cor(ldapp,test)

	r= xtabs(~test+ldapp)
	ldacm[1] =r[1] + ldacm[1]
	ldacm[2] =r[2]+ ldacm[2]
	ldacm[3] =r[3]+ ldacm[3]
	ldacm[4] =r[4]+ ldacm[4]


	#qda model
	#qdam = qda(spam~.,data = data[train ==1,])
	#qdap = predict(qdam, type = "posterior",new = data[train==0,])
	#qdapp = qdap>.5
	#qda[i] = cor(qdapp,test)
	
	#	r= xtabs(~test+qdapp)
	#qdacm[1] =r[1] + qdacm[1]
	#qdacm[2] =r[2]+ qdacm[2]
	#qdacm[3] =r[3]+ qdacm[3]
	#qdacm[4] =r[4]+ qdacm[4]
	

}
mean(rp)	#0.6167784
mean(log)	#0.815587
mean (lda)	#0.7654277
mean(qda)	#0.6811893

rpcm
logcm
ldacm
qdacm
